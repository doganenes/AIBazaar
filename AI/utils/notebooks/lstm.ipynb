{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"products.csv\")\n",
    "# Keep only rows with Price > 0\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"filterNewAkakce.csv\",index=False)\n",
    "print(f\"Original rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\filterPhone.csv\")\n",
    "print(\"İlk 10 satır:\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Birleştirilecek kolonlar\n",
    "columns_to_concat = [\n",
    "    \"storage\",\n",
    "    \"ram\",\n",
    "    \"phone_brand\",\n",
    "    \"phone_model\",  \n",
    "    \"dimensions\",\n",
    "    \"display_size\",\n",
    "    \"display_resolution\",\n",
    "    \"os\",\n",
    "    \"battery\",\n",
    "    \"video\",\n",
    "    \"chipset\",\n",
    "    \"cpu\",\n",
    "    \"gpu\",\n",
    "    \"ppi_density\",\n",
    "]\n",
    "\n",
    "# Yeni DataFrame oluştur\n",
    "result_df = pd.DataFrame(columns=[\"productID\", \"Product Name\", \"description\"])\n",
    "\n",
    "# Her satır için işlem yap\n",
    "for index, row in df.iterrows():\n",
    "    # Boş olmayan değerleri key:value formatında birleştir\n",
    "    description_parts = []\n",
    "\n",
    "    for col in columns_to_concat:\n",
    "        if col in df.columns:  # Kolon varsa\n",
    "            value = row[col]\n",
    "            # NaN, None veya boş değilse ekle\n",
    "            if pd.notna(value) and str(value).strip() != \"\":\n",
    "                description_parts.append(f\"{col}:{value}\")\n",
    "\n",
    "    # Tüm parçaları birleştir\n",
    "    description = \";\".join(description_parts)\n",
    "\n",
    "    # Phone model değerini al\n",
    "    phone_model = (\n",
    "        row[\"phone_model\"]\n",
    "        if \"phone_model\" in df.columns and pd.notna(row[\"phone_model\"])\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    # Yeni DataFrame'e ekle\n",
    "    result_df.loc[index] = [\n",
    "        index + 1,\n",
    "        phone_model,\n",
    "        description,\n",
    "    ]  # Corrected column order\n",
    "\n",
    "    # İlk 5 sonucu göster (test için)\n",
    "\n",
    "# CSV olarak kaydet\n",
    "output_path = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\products_descriptions.csv\"\n",
    ")\n",
    "result_df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nSonuç CSV dosyası kaydedildi: {output_path}\")\n",
    "print(\"\\nOluşturulan CSV yapısı:\")\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\filterNewAkakce.csv'\n",
    "\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "df['Product Name'] = df['Product Name'].str.strip()\n",
    "\n",
    "df.to_csv(input_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8623fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "input_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\filterNewAkakce.csv'\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "# \"Fiyatı\" kolonu hariç diğer tüm kolon adlarını al\n",
    "columns_except_fiyat = [col for col in df.columns if col != 'Price']\n",
    "\n",
    "# Bu kolonlara göre tekrar eden satırları kaldır\n",
    "unique_df = df.drop_duplicates(subset=columns_except_fiyat)\n",
    "\n",
    "# Yeni CSV dosyasını kaydet\n",
    "output_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\withoutDuplicatePrice.csv'\n",
    "unique_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Fiyatı hariç tekrarsız veri kaydedildi: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "input_filename = r\"C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\notebooks\\LstmPriceHistory.csv\"\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "# İndeksi 1'den başlat\n",
    "df.index = range(1, len(df) + 1)\n",
    "\n",
    "# CSV'ye yaz\n",
    "df.to_csv(input_filename, index=True)\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"epeyProductListid.csv\")\n",
    "print(\"before\",len(df))\n",
    "df = df.drop_duplicates(subset=\"ProductID\")\n",
    "print(\"after\",len(df))\n",
    "df.to_csv(\"epeyProductListid.csv\", index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "print(\"before\", len(df))\n",
    "df =df.drop_duplicates()\n",
    "print(\"after\", len(df))\n",
    "df.to_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45327c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV'yi oku\n",
    "df = pd.read_csv(r\"C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\notebooks\\LSTMPriceHistory.csv\")\n",
    "\n",
    "df[\"ProductName\"] = df[\"ProductName\"].apply(lambda x: re.sub(r'[\\/:*?\"<>|]', ' ', x))\n",
    "\n",
    "# Sonuçları kontrol et\n",
    "print(df[\"ProductName\"].head())\n",
    "df.to_csv(\"LSTMPriceHistory.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086da3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\notebooks\\LSTMProduct1.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# Model, RAM ve Hafıza'yı ayıklayan yardımcı fonksiyon\n",
    "def extract_product_name(description):\n",
    "    try:\n",
    "      \n",
    "        ram = re.search(r\"RAM Kapasitesi:\\s*([\\d]+ GB)\", description)\n",
    "        storage = re.search(r\"Dahili Hafıza:\\s*([\\d]+ GB)\", description)\n",
    "\n",
    "        ram_str = ram.group(1).strip() if ram else \"\"\n",
    "        storage_str = storage.group(1).strip() if storage else \"\"\n",
    "\n",
    "        return f\"{ram_str} RAM {storage_str}\".strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df[\"Price\"] = df[\"Price\"].astype(str).str.split(\".\").str[0]  # Fiyatı tam sayıya çevir\n",
    "# Yeni kolonu oluştur\n",
    "df[\"Model\"] = df[\"Model\"]+\" \"+df[\"Description\"].apply(extract_product_name)\n",
    "\n",
    "df.to_csv(\"product_specs_en1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45967061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class LSTMModelEvaluator:\n",
    "    def __init__(self, data_path, model_path, scaler_path, look_back=20):\n",
    "        self.data_path = data_path\n",
    "        self.model_path = model_path\n",
    "        self.scaler_path = scaler_path\n",
    "        self.look_back = look_back\n",
    "\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\")\n",
    "        df[\"RecordDate\"] = pd.to_datetime(df[\"RecordDate\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"RecordDate\", \"Price\"])\n",
    "        return df\n",
    "\n",
    "    def prepare_sequences(self, prices_scaled):\n",
    "        x, y = [], []\n",
    "        for i in range(len(prices_scaled) - self.look_back):\n",
    "            x.append(prices_scaled[i : i + self.look_back])\n",
    "            y.append(prices_scaled[i + self.look_back])\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def evaluate_model_metrics(self, product_id):\n",
    "        # Dosyalar kontrol ediliyor\n",
    "        if not os.path.exists(self.model_path) or not os.path.exists(self.scaler_path):\n",
    "            raise FileNotFoundError(\"Model veya scaler dosyası bulunamadı.\")\n",
    "\n",
    "        # Model ve scaler yükleniyor\n",
    "        model = load_model(self.model_path)\n",
    "        with open(self.scaler_path, \"rb\") as f:\n",
    "            scaler = pickle.load(f)\n",
    "\n",
    "        # Veri yükleniyor\n",
    "        df = self.load_data()\n",
    "        product_df = df[df[\"ProductID\"] == int(product_id)].sort_values(\"RecordDate\")\n",
    "\n",
    "        if len(product_df) < self.look_back + 1:\n",
    "            raise ValueError(\"Değerlendirme için yeterli veri yok.\")\n",
    "\n",
    "        prices = product_df[\"Price\"].values.reshape(-1, 1)\n",
    "        prices_scaled = scaler.transform(prices)\n",
    "        x, y_scaled = self.prepare_sequences(prices_scaled)\n",
    "\n",
    "        # Tahmin yapılıyor\n",
    "        y_pred_scaled = model.predict(x, verbose=0)\n",
    "        y_true = scaler.inverse_transform(y_scaled)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "        # MAE hesapla\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # MAPE ve accuracy hesapla\n",
    "        epsilon = 1e-8  # sıfıra bölme hatası için\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
    "        accuracy = 100 - mape\n",
    "\n",
    "        return {\n",
    "            \"productId\": int(product_id),\n",
    "            \"productName\": product_df[\"ProductName\"].iloc[0],\n",
    "            \"mae\": round(mae, 2),\n",
    "            \"mape\": round(mape, 2),\n",
    "            \"accuracy_percent\": round(accuracy, 2),\n",
    "            \"sample_count\": len(y_true),\n",
    "        }\n",
    "\n",
    "\n",
    "DATA_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\notebooks\\LSTMPriceHistory.csv\"\n",
    ")\n",
    "MODEL_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\models\\general_lstm_model.h5\"\n",
    ")\n",
    "SCALER_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\models\\general_scaler.pkl\"\n",
    ")\n",
    "\n",
    "evaluator = LSTMModelEvaluator(DATA_PATH, MODEL_PATH, SCALER_PATH)\n",
    "result = evaluator.evaluate_model_metrics(product_id=854787)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe27359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tarih ve fiyat verisi (örnek)\n",
    "raw_data = pd.read_csv(\"LSTMPriceHistory.csv\", sep=\"\\t\", header=None, names=[\"RecordDate\", \"Price\"])\n",
    "# Veri işleme\n",
    "lines = [line.strip() for line in raw_data.strip().split(\"\\n\")]\n",
    "records = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        date_str, price_str = line.split(\"\\t\")\n",
    "        date = datetime.strptime(date_str.strip(), \"%d.%m.%Y\")\n",
    "        price = float(price_str.strip().replace(\",\", \".\"))\n",
    "        records.append((date, price))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"RecordDate\", \"Price\"])\n",
    "\n",
    "# Eksik veriler yerine sabit fiyatlar ekle (örnekleme amacıyla)\n",
    "while len(df) < 100:\n",
    "    last_date = df.iloc[-1][\"RecordDate\"]\n",
    "    next_date = last_date + pd.Timedelta(days=1)\n",
    "    df = pd.concat([df, pd.DataFrame({\"RecordDate\": [next_date], \"Price\": [df[\"Price\"].iloc[-1] + np.random.uniform(0, 5)]})], ignore_index=True)\n",
    "\n",
    "# LSTM için veriyi hazırlama\n",
    "scaler = MinMaxScaler()\n",
    "scaled_prices = scaler.fit_transform(df[[\"Price\"]])\n",
    "sequence_length = 10\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(scaled_prices) - sequence_length):\n",
    "    X.append(scaled_prices[i:i+sequence_length])\n",
    "    y.append(scaled_prices[i+sequence_length])\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM model tanımı\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation=\"relu\", input_shape=(sequence_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=30, verbose=1)\n",
    "\n",
    "# 15 gün ileriye tahmin\n",
    "forecast = []\n",
    "last_sequence = scaled_prices[-sequence_length:]\n",
    "for _ in range(15):\n",
    "    input_seq = last_sequence.reshape((1, sequence_length, 1))\n",
    "    pred_scaled = model.predict(input_seq, verbose=0)[0][0]\n",
    "    forecast.append(pred_scaled)\n",
    "    last_sequence = np.append(last_sequence[1:], [[pred_scaled]], axis=0)\n",
    "\n",
    "# Skaler ters dönüşüm (normalize → gerçek fiyat)\n",
    "forecast_prices = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Tahmini yazdır\n",
    "for i, price in enumerate(forecast_prices, 1):\n",
    "    print(f\"Gün {i}: {price:.2f} TL\")\n",
    "\n",
    "# Grafik çiz\n",
    "plt.plot(range(1, 16), forecast_prices, marker='o')\n",
    "plt.title(\"15 Günlük LSTM Fiyat Tahmini\")\n",
    "plt.xlabel(\"Gün\")\n",
    "plt.ylabel(\"Tahmini Fiyat (TL)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Türkçe key -> İngilizce key sözlüğü\n",
    "tr_to_en = {\n",
    "    \"Model\": \"Model\",\n",
    "    \"Ekran Boyutu\": \"Display Size\",\n",
    "    \"Ekran Teknolojisi\": \"Display Technology\",\n",
    "    \"Piksel Yoğunluğu\": \"Pixel Density\",\n",
    "    \"Batarya Kapasitesi\": \"Battery Capacity\",\n",
    "    \"Kamera Çözünürlüğü\": \"Camera Resolution\",\n",
    "    \"CPU Üretim Teknolojisi\": \"CPU Manufacturing\",\n",
    "    \"İşletim Sistemi\": \"Operating System\",\n",
    "    \"RAM Kapasitesi\": \"RAM\",\n",
    "    \"Dahili Hafıza\": \"Internal Storage\",\n",
    "    \"Hızlı Şarj Desteği\": \"Fast Charging Support\",\n",
    "    \"Ekran Yenileme Hızı\": \"Screen Refresh Rate\",\n",
    "    \"5G\": \"5G\",\n",
    "    \"Price\": \"Price\"\n",
    "}\n",
    "\n",
    "def translate_description(desc, tr_to_en):\n",
    "    if pd.isna(desc):\n",
    "        return desc\n",
    "    parts = desc.split(\";\")\n",
    "    new_parts = []\n",
    "    for part in parts:\n",
    "        if \":\" in part:\n",
    "            key, val = part.split(\":\", 1)\n",
    "            key = key.strip()\n",
    "            val = val.strip()\n",
    "            new_key = tr_to_en.get(key, key)  # Çeviri yoksa orijinal key\n",
    "            new_parts.append(f\"{new_key}: {val}\")\n",
    "        else:\n",
    "            new_parts.append(part.strip())\n",
    "    return \"; \".join(new_parts)\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(\"orijinal.csv\")\n",
    "\n",
    "# Description kolonundaki Türkçe keyleri İngilizce'ye çevir\n",
    "df[\"Description\"] = df[\"Description\"].apply(lambda x: translate_description(x, tr_to_en))\n",
    "\n",
    "# Yeni CSV dosyasını kaydet\n",
    "df.to_csv(\"yeni_english_description.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e048f9a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\__init__.py:80\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     ArrowDtype,\n\u001b[0;32m     83\u001b[0m     Int8Dtype,\n\u001b[0;32m     84\u001b[0m     Int16Dtype,\n\u001b[0;32m     85\u001b[0m     Int32Dtype,\n\u001b[0;32m     86\u001b[0m     Int64Dtype,\n\u001b[0;32m     87\u001b[0m     UInt8Dtype,\n\u001b[0;32m     88\u001b[0m     UInt16Dtype,\n\u001b[0;32m     89\u001b[0m     UInt32Dtype,\n\u001b[0;32m     90\u001b[0m     UInt64Dtype,\n\u001b[0;32m     91\u001b[0m     Float32Dtype,\n\u001b[0;32m     92\u001b[0m     Float64Dtype,\n\u001b[0;32m     93\u001b[0m     CategoricalDtype,\n\u001b[0;32m     94\u001b[0m     PeriodDtype,\n\u001b[0;32m     95\u001b[0m     IntervalDtype,\n\u001b[0;32m     96\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     97\u001b[0m     StringDtype,\n\u001b[0;32m     98\u001b[0m     BooleanDtype,\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     NA,\n\u001b[0;32m    101\u001b[0m     isna,\n\u001b[0;32m    102\u001b[0m     isnull,\n\u001b[0;32m    103\u001b[0m     notna,\n\u001b[0;32m    104\u001b[0m     notnull,\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     Index,\n\u001b[0;32m    107\u001b[0m     CategoricalIndex,\n\u001b[0;32m    108\u001b[0m     RangeIndex,\n\u001b[0;32m    109\u001b[0m     MultiIndex,\n\u001b[0;32m    110\u001b[0m     IntervalIndex,\n\u001b[0;32m    111\u001b[0m     TimedeltaIndex,\n\u001b[0;32m    112\u001b[0m     DatetimeIndex,\n\u001b[0;32m    113\u001b[0m     PeriodIndex,\n\u001b[0;32m    114\u001b[0m     IndexSlice,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     NaT,\n\u001b[0;32m    117\u001b[0m     Period,\n\u001b[0;32m    118\u001b[0m     period_range,\n\u001b[0;32m    119\u001b[0m     Timedelta,\n\u001b[0;32m    120\u001b[0m     timedelta_range,\n\u001b[0;32m    121\u001b[0m     Timestamp,\n\u001b[0;32m    122\u001b[0m     date_range,\n\u001b[0;32m    123\u001b[0m     bdate_range,\n\u001b[0;32m    124\u001b[0m     Interval,\n\u001b[0;32m    125\u001b[0m     interval_range,\n\u001b[0;32m    126\u001b[0m     DateOffset,\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     to_numeric,\n\u001b[0;32m    129\u001b[0m     to_datetime,\n\u001b[0;32m    130\u001b[0m     to_timedelta,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     Flags,\n\u001b[0;32m    133\u001b[0m     Grouper,\n\u001b[0;32m    134\u001b[0m     factorize,\n\u001b[0;32m    135\u001b[0m     unique,\n\u001b[0;32m    136\u001b[0m     value_counts,\n\u001b[0;32m    137\u001b[0m     NamedAgg,\n\u001b[0;32m    138\u001b[0m     array,\n\u001b[0;32m    139\u001b[0m     Categorical,\n\u001b[0;32m    140\u001b[0m     set_eng_float_format,\n\u001b[0;32m    141\u001b[0m     Series,\n\u001b[0;32m    142\u001b[0m     DataFrame,\n\u001b[0;32m    143\u001b[0m )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mpandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# --- Veriyi hazırla (senin kodun) ---\n",
    "dates = [datetime.today() - timedelta(days=i) for i in range(100)]\n",
    "dates = sorted(dates)\n",
    "\n",
    "np.random.seed(42)\n",
    "usd_try = np.round(np.random.normal(loc=32, scale=0.3, size=100), 2)\n",
    "usd_try = np.clip(usd_try, 31.5, 32.5)\n",
    "\n",
    "usd_price = 900\n",
    "fluctuation = np.random.normal(0, 100, size=100)\n",
    "prices = usd_try * usd_price + fluctuation\n",
    "prices = np.round(prices, 2)\n",
    "\n",
    "df = pd.DataFrame({\"date\": dates, \"usd_try\": usd_try, \"price_tl\": prices})\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# --- Sadece price_tl kullanacağız ---\n",
    "data = df[[\"price_tl\"]].values\n",
    "\n",
    "# --- Ölçekleme ---\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "# --- Sliding window oluştur ---\n",
    "def create_dataset(dataset, time_step=10):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_step):\n",
    "        X.append(dataset[i : (i + time_step), 0])\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "time_step = 10\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# LSTM giriş şekli (num_samples, time_step, num_features)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# --- Eğitim ve test ayır ---\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# --- Modeli oluştur ---\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# --- Modeli eğit ---\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=8,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# --- Tahmin ---\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# --- Tahminleri orijinal skala döndür ---\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_train_orig = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# --- Grafik için ---\n",
    "train_plot = np.empty_like(scaled_data)\n",
    "train_plot[:, :] = np.nan\n",
    "train_plot[time_step : len(train_predict) + time_step, 0] = train_predict[:, 0]\n",
    "\n",
    "test_plot = np.empty_like(scaled_data)\n",
    "test_plot[:, :] = np.nan\n",
    "test_plot[len(train_predict) + (time_step * 2) : len(scaled_data), 0] = test_predict[\n",
    "    :, 0\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"date\"], data, label=\"Gerçek Fiyat (TL)\")\n",
    "plt.plot(df[\"date\"], train_plot, label=\"Train Tahmin\")\n",
    "plt.plot(df[\"date\"], test_plot, label=\"Test Tahmin\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.ylabel(\"Fiyat (TL)\")\n",
    "plt.title(\"iPhone 13 TL Fiyatı - LSTM Tahmini\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
