{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"products.csv\")\n",
    "# Keep only rows with Price > 0\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"filterNewAkakce.csv\",index=False)\n",
    "print(f\"Original rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\filterPhone.csv\")\n",
    "print(\"İlk 10 satır:\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Birleştirilecek kolonlar\n",
    "columns_to_concat = [\n",
    "    \"storage\",\n",
    "    \"ram\",\n",
    "    \"phone_brand\",\n",
    "    \"phone_model\",  \n",
    "    \"dimensions\",\n",
    "    \"display_size\",\n",
    "    \"display_resolution\",\n",
    "    \"os\",\n",
    "    \"battery\",\n",
    "    \"video\",\n",
    "    \"chipset\",\n",
    "    \"cpu\",\n",
    "    \"gpu\",\n",
    "    \"ppi_density\",\n",
    "]\n",
    "\n",
    "# Yeni DataFrame oluştur\n",
    "result_df = pd.DataFrame(columns=[\"productID\", \"Product Name\", \"description\"])\n",
    "\n",
    "# Her satır için işlem yap\n",
    "for index, row in df.iterrows():\n",
    "    # Boş olmayan değerleri key:value formatında birleştir\n",
    "    description_parts = []\n",
    "\n",
    "    for col in columns_to_concat:\n",
    "        if col in df.columns:  # Kolon varsa\n",
    "            value = row[col]\n",
    "            # NaN, None veya boş değilse ekle\n",
    "            if pd.notna(value) and str(value).strip() != \"\":\n",
    "                description_parts.append(f\"{col}:{value}\")\n",
    "\n",
    "    # Tüm parçaları birleştir\n",
    "    description = \";\".join(description_parts)\n",
    "\n",
    "    # Phone model değerini al\n",
    "    phone_model = (\n",
    "        row[\"phone_model\"]\n",
    "        if \"phone_model\" in df.columns and pd.notna(row[\"phone_model\"])\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    # Yeni DataFrame'e ekle\n",
    "    result_df.loc[index] = [\n",
    "        index + 1,\n",
    "        phone_model,\n",
    "        description,\n",
    "    ]  # Corrected column order\n",
    "\n",
    "    # İlk 5 sonucu göster (test için)\n",
    "\n",
    "# CSV olarak kaydet\n",
    "output_path = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\products_descriptions.csv\"\n",
    ")\n",
    "result_df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nSonuç CSV dosyası kaydedildi: {output_path}\")\n",
    "print(\"\\nOluşturulan CSV yapısı:\")\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\filterNewAkakce.csv'\n",
    "\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "df['Product Name'] = df['Product Name'].str.strip()\n",
    "\n",
    "df.to_csv(input_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8623fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "input_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\filterNewAkakce.csv'\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "# \"Fiyatı\" kolonu hariç diğer tüm kolon adlarını al\n",
    "columns_except_fiyat = [col for col in df.columns if col != 'Price']\n",
    "\n",
    "# Bu kolonlara göre tekrar eden satırları kaldır\n",
    "unique_df = df.drop_duplicates(subset=columns_except_fiyat)\n",
    "\n",
    "# Yeni CSV dosyasını kaydet\n",
    "output_filename = r'C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\withoutDuplicatePrice.csv'\n",
    "unique_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Fiyatı hariç tekrarsız veri kaydedildi: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını oku\n",
    "input_filename = r\"C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\notebooks\\LstmPriceHistory.csv\"\n",
    "df = pd.read_csv(input_filename)\n",
    "\n",
    "# İndeksi 1'den başlat\n",
    "df.index = range(1, len(df) + 1)\n",
    "\n",
    "# CSV'ye yaz\n",
    "df.to_csv(input_filename, index=True)\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"epeyProductListid.csv\")\n",
    "print(\"before\",len(df))\n",
    "df = df.drop_duplicates(subset=\"ProductID\")\n",
    "print(\"after\",len(df))\n",
    "df.to_csv(\"epeyProductListid.csv\", index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "print(\"before\", len(df))\n",
    "df =df.drop_duplicates()\n",
    "print(\"after\", len(df))\n",
    "df.to_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45327c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV'yi oku\n",
    "df = pd.read_csv(r\"C:\\Users\\EXCALIBUR\\Desktop\\projects\\Okul Ödevler\\AIBazaar\\AI\\utils\\notebooks\\LSTMPriceHistory.csv\")\n",
    "\n",
    "df[\"ProductName\"] = df[\"ProductName\"].apply(lambda x: re.sub(r'[\\/:*?\"<>|]', ' ', x))\n",
    "\n",
    "# Sonuçları kontrol et\n",
    "print(df[\"ProductName\"].head())\n",
    "df.to_csv(\"LSTMPriceHistory.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086da3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\notebooks\\LSTMProduct1.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# Model, RAM ve Hafıza'yı ayıklayan yardımcı fonksiyon\n",
    "def extract_product_name(description):\n",
    "    try:\n",
    "      \n",
    "        ram = re.search(r\"RAM Kapasitesi:\\s*([\\d]+ GB)\", description)\n",
    "        storage = re.search(r\"Dahili Hafıza:\\s*([\\d]+ GB)\", description)\n",
    "\n",
    "        ram_str = ram.group(1).strip() if ram else \"\"\n",
    "        storage_str = storage.group(1).strip() if storage else \"\"\n",
    "\n",
    "        return f\"{ram_str} RAM {storage_str}\".strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df[\"Price\"] = df[\"Price\"].astype(str).str.split(\".\").str[0]  # Fiyatı tam sayıya çevir\n",
    "# Yeni kolonu oluştur\n",
    "df[\"Model\"] = df[\"Model\"]+\" \"+df[\"Description\"].apply(extract_product_name)\n",
    "\n",
    "df.to_csv(\"product_specs_en1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45967061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class LSTMModelEvaluator:\n",
    "    def __init__(self, data_path, model_path, scaler_path, look_back=20):\n",
    "        self.data_path = data_path\n",
    "        self.model_path = model_path\n",
    "        self.scaler_path = scaler_path\n",
    "        self.look_back = look_back\n",
    "\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\")\n",
    "        df[\"RecordDate\"] = pd.to_datetime(df[\"RecordDate\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"RecordDate\", \"Price\"])\n",
    "        return df\n",
    "\n",
    "    def prepare_sequences(self, prices_scaled):\n",
    "        x, y = [], []\n",
    "        for i in range(len(prices_scaled) - self.look_back):\n",
    "            x.append(prices_scaled[i : i + self.look_back])\n",
    "            y.append(prices_scaled[i + self.look_back])\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def evaluate_model_metrics(self, product_id):\n",
    "        # Dosyalar kontrol ediliyor\n",
    "        if not os.path.exists(self.model_path) or not os.path.exists(self.scaler_path):\n",
    "            raise FileNotFoundError(\"Model veya scaler dosyası bulunamadı.\")\n",
    "\n",
    "        # Model ve scaler yükleniyor\n",
    "        model = load_model(self.model_path)\n",
    "        with open(self.scaler_path, \"rb\") as f:\n",
    "            scaler = pickle.load(f)\n",
    "\n",
    "        # Veri yükleniyor\n",
    "        df = self.load_data()\n",
    "        product_df = df[df[\"ProductID\"] == int(product_id)].sort_values(\"RecordDate\")\n",
    "\n",
    "        if len(product_df) < self.look_back + 1:\n",
    "            raise ValueError(\"Değerlendirme için yeterli veri yok.\")\n",
    "\n",
    "        prices = product_df[\"Price\"].values.reshape(-1, 1)\n",
    "        prices_scaled = scaler.transform(prices)\n",
    "        x, y_scaled = self.prepare_sequences(prices_scaled)\n",
    "\n",
    "        # Tahmin yapılıyor\n",
    "        y_pred_scaled = model.predict(x, verbose=0)\n",
    "        y_true = scaler.inverse_transform(y_scaled)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "        # MAE hesapla\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # MAPE ve accuracy hesapla\n",
    "        epsilon = 1e-8  # sıfıra bölme hatası için\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
    "        accuracy = 100 - mape\n",
    "\n",
    "        return {\n",
    "            \"productId\": int(product_id),\n",
    "            \"productName\": product_df[\"ProductName\"].iloc[0],\n",
    "            \"mae\": round(mae, 2),\n",
    "            \"mape\": round(mape, 2),\n",
    "            \"accuracy_percent\": round(accuracy, 2),\n",
    "            \"sample_count\": len(y_true),\n",
    "        }\n",
    "\n",
    "\n",
    "DATA_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\notebooks\\LSTMPriceHistory.csv\"\n",
    ")\n",
    "MODEL_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\models\\general_lstm_model.h5\"\n",
    ")\n",
    "SCALER_PATH = (\n",
    "    r\"C:\\Users\\pc\\Desktop\\AIbazaar\\AIBazaar\\AI\\utils\\models\\general_scaler.pkl\"\n",
    ")\n",
    "\n",
    "evaluator = LSTMModelEvaluator(DATA_PATH, MODEL_PATH, SCALER_PATH)\n",
    "result = evaluator.evaluate_model_metrics(product_id=854787)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe27359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tarih ve fiyat verisi (örnek)\n",
    "raw_data = pd.read_csv(\"LSTMPriceHistory.csv\", sep=\"\\t\", header=None, names=[\"RecordDate\", \"Price\"])\n",
    "# Veri işleme\n",
    "lines = [line.strip() for line in raw_data.strip().split(\"\\n\")]\n",
    "records = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        date_str, price_str = line.split(\"\\t\")\n",
    "        date = datetime.strptime(date_str.strip(), \"%d.%m.%Y\")\n",
    "        price = float(price_str.strip().replace(\",\", \".\"))\n",
    "        records.append((date, price))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"RecordDate\", \"Price\"])\n",
    "\n",
    "# Eksik veriler yerine sabit fiyatlar ekle (örnekleme amacıyla)\n",
    "while len(df) < 100:\n",
    "    last_date = df.iloc[-1][\"RecordDate\"]\n",
    "    next_date = last_date + pd.Timedelta(days=1)\n",
    "    df = pd.concat([df, pd.DataFrame({\"RecordDate\": [next_date], \"Price\": [df[\"Price\"].iloc[-1] + np.random.uniform(0, 5)]})], ignore_index=True)\n",
    "\n",
    "# LSTM için veriyi hazırlama\n",
    "scaler = MinMaxScaler()\n",
    "scaled_prices = scaler.fit_transform(df[[\"Price\"]])\n",
    "sequence_length = 10\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(scaled_prices) - sequence_length):\n",
    "    X.append(scaled_prices[i:i+sequence_length])\n",
    "    y.append(scaled_prices[i+sequence_length])\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM model tanımı\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation=\"relu\", input_shape=(sequence_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=30, verbose=1)\n",
    "\n",
    "# 15 gün ileriye tahmin\n",
    "forecast = []\n",
    "last_sequence = scaled_prices[-sequence_length:]\n",
    "for _ in range(15):\n",
    "    input_seq = last_sequence.reshape((1, sequence_length, 1))\n",
    "    pred_scaled = model.predict(input_seq, verbose=0)[0][0]\n",
    "    forecast.append(pred_scaled)\n",
    "    last_sequence = np.append(last_sequence[1:], [[pred_scaled]], axis=0)\n",
    "\n",
    "# Skaler ters dönüşüm (normalize → gerçek fiyat)\n",
    "forecast_prices = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Tahmini yazdır\n",
    "for i, price in enumerate(forecast_prices, 1):\n",
    "    print(f\"Gün {i}: {price:.2f} TL\")\n",
    "\n",
    "# Grafik çiz\n",
    "plt.plot(range(1, 16), forecast_prices, marker='o')\n",
    "plt.title(\"15 Günlük LSTM Fiyat Tahmini\")\n",
    "plt.xlabel(\"Gün\")\n",
    "plt.ylabel(\"Tahmini Fiyat (TL)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def train_and_forecast_lstm(csv_path, product_id, forecast_days=15, sequence_length=10, epochs=30):\n",
    "    # CSV'den veriyi oku\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    \n",
    "    # productID filtresi\n",
    "    df_product = df_raw[df_raw['ProductID'] == product_id].copy()\n",
    "    \n",
    "    # Tarih formatı varsa datetime yap (tarih string formatını uygun şekilde ayarla)\n",
    "    if df_product['RecordDate'].dtype == object:\n",
    "        df_product['RecordDate'] = pd.to_datetime(df_product['RecordDate'], dayfirst=True, errors='coerce')\n",
    "    \n",
    "    df_product = df_product.dropna(subset=['RecordDate', 'Price'])\n",
    "    \n",
    "    # Tarihe göre sırala\n",
    "    df_product = df_product.sort_values('RecordDate').reset_index(drop=True)\n",
    "    \n",
    "    # Eğer veri çok azsa, eksik günleri fiyatın son değerini kullanarak doldurabiliriz\n",
    "    while len(df_product) < 100:\n",
    "        last_date = df_product.iloc[-1]['RecordDate']\n",
    "        next_date = last_date + pd.Timedelta(days=1)\n",
    "        last_price = df_product.iloc[-1]['Price']\n",
    "        df_product = pd.concat([df_product, pd.DataFrame({\n",
    "            'ProductID': [product_id],\n",
    "            'RecordDate': [next_date],\n",
    "            'Price': [last_price + np.random.uniform(0, 5)]\n",
    "        })], ignore_index=True)\n",
    "    \n",
    "    # Fiyatları ölçeklendir\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_prices = scaler.fit_transform(df_product[['Price']])\n",
    "    \n",
    "    # Eğitim verisi hazırla\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_prices) - sequence_length):\n",
    "        X.append(scaled_prices[i:i+sequence_length])\n",
    "        y.append(scaled_prices[i+sequence_length])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    # Model oluştur\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Modeli eğit\n",
    "    model.fit(X, y, epochs=epochs, verbose=1)\n",
    "    \n",
    "    # Tahmin yap (forecast_days kadar)\n",
    "    forecast = []\n",
    "    last_sequence = scaled_prices[-sequence_length:]\n",
    "    for _ in range(forecast_days):\n",
    "        input_seq = last_sequence.reshape((1, sequence_length, 1))\n",
    "        pred_scaled = model.predict(input_seq, verbose=0)[0][0]\n",
    "        forecast.append(pred_scaled)\n",
    "        last_sequence = np.append(last_sequence[1:], [[pred_scaled]], axis=0)\n",
    "    \n",
    "    # Skaler ters dönüşüm\n",
    "    forecast_prices = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Sonuçları yazdır\n",
    "    print(f\"ProductID: {product_id} için {forecast_days} günlük tahmin:\")\n",
    "    for i, price in enumerate(forecast_prices, 1):\n",
    "        print(f\"Gün {i}: {price:.2f} TL\")\n",
    "    \n",
    "    # Grafik çiz\n",
    "    plt.plot(range(1, forecast_days + 1), forecast_prices, marker='o')\n",
    "    plt.title(f\"{product_id} - {forecast_days} Günlük LSTM Fiyat Tahmini\")\n",
    "    plt.xlabel(\"Gün\")\n",
    "    plt.ylabel(\"Tahmini Fiyat (TL)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Kullanım örneği\n",
    "train_and_forecast_lstm(\"LSTMPriceHistory.csv\", product_id=895855)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Türkçe key -> İngilizce key sözlüğü\n",
    "tr_to_en = {\n",
    "    \"Model\": \"Model\",\n",
    "    \"Ekran Boyutu\": \"Display Size\",\n",
    "    \"Ekran Teknolojisi\": \"Display Technology\",\n",
    "    \"Piksel Yoğunluğu\": \"Pixel Density\",\n",
    "    \"Batarya Kapasitesi\": \"Battery Capacity\",\n",
    "    \"Kamera Çözünürlüğü\": \"Camera Resolution\",\n",
    "    \"CPU Üretim Teknolojisi\": \"CPU Manufacturing\",\n",
    "    \"İşletim Sistemi\": \"Operating System\",\n",
    "    \"RAM Kapasitesi\": \"RAM\",\n",
    "    \"Dahili Hafıza\": \"Internal Storage\",\n",
    "    \"Hızlı Şarj Desteği\": \"Fast Charging Support\",\n",
    "    \"Ekran Yenileme Hızı\": \"Screen Refresh Rate\",\n",
    "    \"5G\": \"5G\",\n",
    "    \"Price\": \"Price\"\n",
    "}\n",
    "\n",
    "def translate_description(desc, tr_to_en):\n",
    "    if pd.isna(desc):\n",
    "        return desc\n",
    "    parts = desc.split(\";\")\n",
    "    new_parts = []\n",
    "    for part in parts:\n",
    "        if \":\" in part:\n",
    "            key, val = part.split(\":\", 1)\n",
    "            key = key.strip()\n",
    "            val = val.strip()\n",
    "            new_key = tr_to_en.get(key, key)  # Çeviri yoksa orijinal key\n",
    "            new_parts.append(f\"{new_key}: {val}\")\n",
    "        else:\n",
    "            new_parts.append(part.strip())\n",
    "    return \"; \".join(new_parts)\n",
    "\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(\"orijinal.csv\")\n",
    "\n",
    "# Description kolonundaki Türkçe keyleri İngilizce'ye çevir\n",
    "df[\"Description\"] = df[\"Description\"].apply(lambda x: translate_description(x, tr_to_en))\n",
    "\n",
    "# Yeni CSV dosyasını kaydet\n",
    "df.to_csv(\"yeni_english_description.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
